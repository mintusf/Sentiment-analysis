{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment_analysis_model_training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mintusf/Sentiment-analysis/blob/master/Sentiment_analysis_model_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uvx5wizW4Flw",
        "colab_type": "text"
      },
      "source": [
        "To download dataset and glove embeddings, you need an account on kaggle.\n",
        "Download kaggle.json from My account -> API -> Create New API Token\n",
        "\n",
        "In order to run notebook without crashing, I recommend setting RAM to max. 25GB."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKpvR8wI92aQ",
        "colab_type": "text"
      },
      "source": [
        "**Downloading data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kG2BjYES5vbt",
        "colab_type": "code",
        "outputId": "78d0717c-6bb3-492b-927b-89beddcbb830",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        }
      },
      "source": [
        "from google.colab import files"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_qWPmcf4wsY",
        "colab_type": "text"
      },
      "source": [
        "Choose the kaggle.json file that you have downloaded"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpjhU2_z58eK",
        "colab_type": "code",
        "outputId": "158ec322-e75f-4855-a8c0-566c4389138f",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "files.upload()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2d1edae0-b9f4-4965-93b0-16baffea2137\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-2d1edae0-b9f4-4965-93b0-16baffea2137\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"filipmintus\",\"key\":\"6f72d4148a17a65140b68eee58af8fb2\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_KfdoOc405K",
        "colab_type": "text"
      },
      "source": [
        "File configuration in order to use in google colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jBANPLK5-fQ",
        "colab_type": "code",
        "outputId": "6ef21aa4-3f88-4da1-a510-2be4322e5e86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls -lha kaggle.json\n",
        "!mkdir -p ~/.kaggle \n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 67 Dec 11 11:29 kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXK8rqxR5B0k",
        "colab_type": "text"
      },
      "source": [
        "Download and extract the dataset - Amazon reviews.\n",
        "\n",
        "The dataset includes 3600000 reviews of Amazon products in the training dataset and 400000 reviews in the testing dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZSrkH116Tqv",
        "colab_type": "code",
        "outputId": "718eeb04-e2da-4baa-e4f3-235f79c50429",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "!kaggle datasets download bittlingmayer/amazonreviews\n",
        "!unzip amazonreviews.zip"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading amazonreviews.zip to /content\n",
            " 98% 481M/493M [00:04<00:00, 110MB/s] \n",
            "100% 493M/493M [00:04<00:00, 111MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z94HBjMf5m4d",
        "colab_type": "text"
      },
      "source": [
        "Extracting examples and labels\n",
        "\n",
        "1. Opening Bz2 file\n",
        "2. Decoding byte type\n",
        "3. Extracting label from a string"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eo7i566ATzHj",
        "colab_type": "code",
        "outputId": "81a2b0f6-096d-405f-f39f-24405e495b11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "import bz2\n",
        "with bz2.open(\"test.ft.txt.bz2\", \"rb\") as f:\n",
        "  # Decompress data from file\n",
        "  content = f.read()\n",
        "text = content.decode()\n",
        "text = text.split('__label__')[1:]\n",
        "Y_test = [a[0] for a in text]\n",
        "X_test = [a[2:] for a in text]\n",
        "print(len(X_test)==len(Y_test))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "2 Useful for remodels: I recently remodeled my house and these came in extremely useful for boring through studs for electrical and plumbing... as well as prepping doors for hardware.\n",
            "\n",
            "Useful for remodels: I recently remodeled my house and these came in extremely useful for boring through studs for electrical and plumbing... as well as prepping doors for hardware.\n",
            "\n",
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYOe8xGKpebb",
        "colab_type": "code",
        "outputId": "abfc082c-39b7-4d78-8f83-41fd7d23fddc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import bz2\n",
        "with bz2.open(\"train.ft.txt.bz2\", \"rb\") as f:\n",
        "  # Decompress data from file\n",
        "  content = f.read()\n",
        "text = content.decode()\n",
        "text = text.split('__label__')[1:]\n",
        "Y_train = [a[0] for a in text]\n",
        "X_train = [a[2:] for a in text]\n",
        "print(len(X_train)==len(Y_train))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sbext_Sg8F57",
        "colab_type": "text"
      },
      "source": [
        "Downloading 100-dimensional GloVe embedding with 6 billions tokens. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nf83BSemoOfM",
        "colab_type": "code",
        "outputId": "c4987fd8-4ea1-4159-d9a0-923c17642454",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "!kaggle datasets download terenceliu4444/glove6b100dtxt\n",
        "!unzip glove6b100dtxt"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading glove6b100dtxt.zip to /content\n",
            " 90% 118M/131M [00:01<00:00, 70.9MB/s]\n",
            "100% 131M/131M [00:01<00:00, 97.3MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZHyFVHu8xOO",
        "colab_type": "text"
      },
      "source": [
        "A function for extracting look-up dictionaries between words, indexes and embeddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9J1KrDGDwEV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_glove_vecs(glove_file):\n",
        "    with open(glove_file, 'r') as f:\n",
        "        words = set()\n",
        "        word_to_vec_map = {}\n",
        "        for line in f:\n",
        "            line = line.strip().split()\n",
        "            curr_word = line[0]\n",
        "            words.add(curr_word)\n",
        "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)       \n",
        "        i = 1\n",
        "        words_to_index = {}\n",
        "        index_to_words = {}\n",
        "        for w in sorted(words):\n",
        "            words_to_index[w] = i\n",
        "            index_to_words[i] = w\n",
        "            i = i + 1\n",
        "    return words_to_index, index_to_words, word_to_vec_map"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVqgWtg6D-I5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "words_to_index, index_to_words, word_to_vec_map = read_glove_vecs('glove.6B.100d.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZ1TH9wa-PbV",
        "colab_type": "text"
      },
      "source": [
        "**Data preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2kGX_3SGXas",
        "colab_type": "text"
      },
      "source": [
        "Function for splitting each sentence from input vector into list containing embedding index corresponding to each word of sentence. Outputted list will be an input for the Embedding layer of Keras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmKKAy3rfSXx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_sentence(sentences, words_to_index,max_words):\n",
        "  m = len(sentences)\n",
        "  new_sentences = []\n",
        "  for i, sentence  in enumerate(sentences):\n",
        "    words = sentence.lower().split()\n",
        "    new_sentence = []\n",
        "    for j,word in enumerate(words):\n",
        "      if word[-1] in [',', '.', ':','!','?' ,' ', ',','''\\'''']:\n",
        "        word = word[:-1]\n",
        "      if word in words_to_index.keys():\n",
        "        new_sentence.append(words_to_index[word])\n",
        "      else: new_sentence.append(0)\n",
        "    new_sentences.append(new_sentence)\n",
        "  return new_sentences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFETOLTQ8-cG",
        "colab_type": "text"
      },
      "source": [
        "Splitting training dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgdM9UMxe2gl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_indices = split_sentence(X_train, words_to_index, 150)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuVLKCcHqPDg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test_indices = split_sentence(X_test, words_to_index, 150)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BE7ZlmFw9X8C",
        "colab_type": "text"
      },
      "source": [
        "Next step is to pad sentences into the same length (150).\n",
        "Too long sentences are cutted at the beginning.\n",
        "Too short sentences are filled with 0 in the beginning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5WymMlhgm9p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "X_train_padded = pad_sequences(X_train_indices,maxlen = 150, padding='pre', truncating='pre')\n",
        "X_test_padded = pad_sequences(X_test_indices,maxlen = 150, padding='pre', truncating='pre')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uzdkbyKDHDf",
        "colab_type": "text"
      },
      "source": [
        "Correcting labels, so that 1 corresponds to positive sentiment and 0 to negative."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "729ZBGcSDCwH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_train = np.array(Y_train, dtype = np.int32)\n",
        "Y_train-=1\n",
        "Y_test_true = np.array(Y_test, dtype = np.int32)\n",
        "Y_test_true-=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYZVBPeT-npr",
        "colab_type": "text"
      },
      "source": [
        "**Model building**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhrFQwsMFPpk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Embedding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4evtDk6SCnXZ",
        "colab_type": "text"
      },
      "source": [
        "A function creating an embedding layer with the pre-trained gloVe embeddings.\n",
        "Weights of the Embedding layer are set to be trainable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLE05b0vHoEr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_embedding_layer(word_to_vec_map, words_to_index):\n",
        "  voc_size = len(words_to_index) + 1\n",
        "  emb_dim = word_to_vec_map['rice'].shape[0]\n",
        "  emb_matrix = np.zeros((voc_size,emb_dim))\n",
        "  for word, index in words_to_index.items():\n",
        "    emb_matrix[index,:] = word_to_vec_map[word]\n",
        "  embedding_layer = Embedding(voc_size, emb_dim, trainable = True)\n",
        "  embedding_layer.build((None,))\n",
        "  embedding_layer.set_weights([emb_matrix])\n",
        "  return embedding_layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHGfmnqllQxC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "first_layer = build_embedding_layer(word_to_vec_map, words_to_index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1TuPIitCydi",
        "colab_type": "text"
      },
      "source": [
        "A function building a NLP model for sentiment analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpmrsYFbox6e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
        "\n",
        "def build_sentiment_model(input_shape, word_to_vec_map,words_to_index):\n",
        "  sentence_input = Input((input_shape),dtype = 'int32')\n",
        "  \n",
        "  embedding_layer = build_embedding_layer(word_to_vec_map,words_to_index)\n",
        "  X = embedding_layer(sentence_input)\n",
        "  X = LSTM(256,return_sequences = True)(X)\n",
        "  X = Dropout(0.1)(X)\n",
        "  X = LSTM(256,return_sequences = False)(X)\n",
        "  X = Dropout(0.1)(X)\n",
        "  X = Dense(1)(X)\n",
        "  X = Activation('sigmoid')(X)\n",
        "\n",
        "  model = Model (sentence_input, X)\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeqxBlq0thmT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentiment_model = build_sentiment_model((150,),word_to_vec_map, words_to_index)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4qGi4dPzUI8",
        "colab_type": "code",
        "outputId": "2ac3b23c-30b5-49f1-bc5d-934698a848be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        }
      },
      "source": [
        "sentiment_model.summary()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 150)]             0         \n",
            "_________________________________________________________________\n",
            "embedding_5 (Embedding)      (None, 150, 100)          40000100  \n",
            "_________________________________________________________________\n",
            "lstm_6 (LSTM)                (None, 150, 256)          365568    \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 150, 256)          0         \n",
            "_________________________________________________________________\n",
            "lstm_7 (LSTM)                (None, 256)               525312    \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 257       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 40,891,237\n",
            "Trainable params: 40,891,237\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0PZzgMEtviw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "sentiment_model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate = 0.0001), metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_IYEuZ2DQ7v",
        "colab_type": "text"
      },
      "source": [
        "The training dataset consists of 3600000 examples. In order to make training faster, random 200000 examples are chosen for this process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GS81J2EFplN8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx = np.random.randint(0,3600000,200000)\n",
        "X_train_padded_part = X_train_padded[idx]\n",
        "Y_train_padded_part = Y_train[idx]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4ZSDCmhDbXN",
        "colab_type": "text"
      },
      "source": [
        "Training the model with batch size 128 for 2 epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlirAU45vWuw",
        "colab_type": "code",
        "outputId": "e3c8876a-5115-4621-bb32-407f91d25584",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "with tf.device('/device:GPU:0'):\n",
        "  sentiment_model.fit(X_train_padded_part,Y_train_padded_part,batch_size = 128, epochs = 2, shuffle = True)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 200000 samples\n",
            "Epoch 1/2\n",
            "200000/200000 [==============================] - 602s 3ms/sample - loss: 0.4115 - acc: 0.8118\n",
            "Epoch 2/2\n",
            "200000/200000 [==============================] - 594s 3ms/sample - loss: 0.2927 - acc: 0.8777\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRRFEha-Dfk1",
        "colab_type": "text"
      },
      "source": [
        "Training the model for additional 4 epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hz54iJlT1pzW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "e63d7ee1-3fe4-42f2-ed4c-d77aa5b636dc"
      },
      "source": [
        "import tensorflow as tf\n",
        "with tf.device('/device:GPU:0'):\n",
        "  sentiment_model.fit(X_train_padded_part,Y_train_padded_part,batch_size = 128, epochs = 4, shuffle = True)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 200000 samples\n",
            "Epoch 1/4\n",
            "200000/200000 [==============================] - 606s 3ms/sample - loss: 0.2474 - acc: 0.8991\n",
            "Epoch 2/4\n",
            "200000/200000 [==============================] - 597s 3ms/sample - loss: 0.2239 - acc: 0.9105\n",
            "Epoch 3/4\n",
            "200000/200000 [==============================] - 595s 3ms/sample - loss: 0.2070 - acc: 0.9182\n",
            "Epoch 4/4\n",
            "200000/200000 [==============================] - 600s 3ms/sample - loss: 0.1920 - acc: 0.9249\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwfwwtszD2yo",
        "colab_type": "text"
      },
      "source": [
        "The model reaches 92.5% on training dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YigrZNNeDwr3",
        "colab_type": "text"
      },
      "source": [
        "Evaluating the model with 100000 randomly chosen examples from test dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNAJeG1vsKEJ",
        "colab_type": "code",
        "outputId": "f1fc6d8a-6af7-4dca-8e24-590e2b2c1780",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "idx = np.random.randint(0,400000,100000)\n",
        "sentiment_model.evaluate(X_test_padded[idx], Y_test_true[idx])"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100000/100000 [==============================] - 254s 3ms/sample - loss: 0.2217 - acc: 0.9118\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.22167939500808717, 0.91177]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooEEn1pgD7cs",
        "colab_type": "text"
      },
      "source": [
        "Let's try our own sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wst_SqZiosXq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_sentiment(sentence):\n",
        "  X_test = split_sentence(sentence, words_to_index, 150)\n",
        "  X_test_padded = pad_sequences(X_test,maxlen = 150)\n",
        "  prediction = sentiment_model.predict(X_test_padded)\n",
        "  if prediction > 0.5: print ('Positive!')\n",
        "  else: print('Negative!')\n",
        "  print(prediction)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZOscbrXECUt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "367197fc-5599-4422-92eb-34583d42438c"
      },
      "source": [
        "predict_sentiment(['Such an amazing quality!'])"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive!\n",
            "[[0.7540016]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4sPy148ELUN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "05194aa0-90a6-45ab-805c-12d1fe3d2fd0"
      },
      "source": [
        "predict_sentiment(['Great purchase! After one year still looks like new'])"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive!\n",
            "[[0.91678673]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iy8guhzAEUY7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "25ea89fc-3b4d-48b9-a388-fca1148915a3"
      },
      "source": [
        "predict_sentiment(['It is so bad that I would not recommend it even to my worst enemy'])"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Negative!\n",
            "[[0.0311656]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqgdz2PpEknv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "ad997899-5abb-4351-c896-69e40d02b5aa"
      },
      "source": [
        "predict_sentiment(['Broken after second use.'])"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Negative!\n",
            "[[0.10456979]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MAJBMMmI4BK",
        "colab_type": "text"
      },
      "source": [
        "Run next cell if you want to save weights on you Google Drive.\n",
        "\n",
        "To do it, you need to click the shown link, choose your google account and allow Google Cloud SDK to access it. The password will be shown which should be inputed in blank area."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GL_j2XfMIAIq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a5f40d13-3e58-486b-9912-2210aab57004"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "sentiment_model.save_weights('SentimentModel_weights.h5')\n",
        "weights_file = drive.CreateFile({'title' : 'SentimentModel_weights.h5'})\n",
        "weights_file.SetContentFile('SentimentModel_weights.h5')\n",
        "weights_file.Upload()\n",
        "drive.CreateFile({'id': weights_file.get('id')})\n",
        "print(f\"Weights saved, id: {weights_file.get('''id''')}\")"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Weights saved, id: 1DDr_sZZRuVwXqyhsOGJ_-l6gXPThEvfh\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}